{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://youtube.com/watch?v=qhRNvCVVJaA\n",
    "#https://www.youtube.com/watch?v=mo96Nqlo1L8\n",
    "#https://www.youtube.com/watch?v=HGeI30uATws\n",
    "#https://www.datamachinist.com/reinforcement-learning/part-6-q-learning-for-continuous-state-problems/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0  score for ep 1\n",
      "18.0  score for ep 2\n",
      "15.0  score for ep 3\n",
      "23.0  score for ep 4\n",
      "15.0  score for ep 5\n",
      "10.0  score for ep 6\n",
      "22.0  score for ep 7\n",
      "16.0  score for ep 8\n",
      "13.0  score for ep 9\n",
      "17.0  score for ep 10\n",
      "23.0  score for ep 11\n",
      "12.0  score for ep 12\n",
      "11.0  score for ep 13\n",
      "23.0  score for ep 14\n",
      "20.0  score for ep 15\n",
      "25.0  score for ep 16\n",
      "11.0  score for ep 17\n",
      "20.0  score for ep 18\n",
      "16.0  score for ep 19\n",
      "20.0  score for ep 20\n",
      "34.0  score for ep 21\n",
      "17.0  score for ep 22\n",
      "22.0  score for ep 23\n",
      "31.0  score for ep 24\n",
      "12.0  score for ep 25\n",
      "18.0  score for ep 26\n",
      "55.0  score for ep 27\n",
      "17.0  score for ep 28\n",
      "14.0  score for ep 29\n",
      "10.0  score for ep 30\n",
      "26.0  score for ep 31\n",
      "52.0  score for ep 32\n",
      "18.0  score for ep 33\n",
      "31.0  score for ep 34\n",
      "44.0  score for ep 35\n",
      "15.0  score for ep 36\n",
      "29.0  score for ep 37\n",
      "16.0  score for ep 38\n",
      "19.0  score for ep 39\n",
      "24.0  score for ep 40\n",
      "27.0  score for ep 41\n",
      "24.0  score for ep 42\n",
      "16.0  score for ep 43\n",
      "11.0  score for ep 44\n",
      "16.0  score for ep 45\n",
      "11.0  score for ep 46\n",
      "41.0  score for ep 47\n",
      "30.0  score for ep 48\n",
      "53.0  score for ep 49\n",
      "11.0  score for ep 50\n",
      "28.0  score for ep 51\n",
      "20.0  score for ep 52\n",
      "13.0  score for ep 53\n",
      "102.0  score for ep 54\n",
      "61.0  score for ep 55\n",
      "64.0  score for ep 56\n",
      "28.0  score for ep 57\n",
      "26.0  score for ep 58\n",
      "27.0  score for ep 59\n",
      "26.0  score for ep 60\n",
      "25.0  score for ep 61\n",
      "57.0  score for ep 62\n",
      "19.0  score for ep 63\n",
      "34.0  score for ep 64\n",
      "44.0  score for ep 65\n",
      "36.0  score for ep 66\n",
      "23.0  score for ep 67\n",
      "40.0  score for ep 68\n",
      "15.0  score for ep 69\n",
      "20.0  score for ep 70\n",
      "60.0  score for ep 71\n",
      "22.0  score for ep 72\n",
      "27.0  score for ep 73\n",
      "37.0  score for ep 74\n",
      "15.0  score for ep 75\n",
      "29.0  score for ep 76\n",
      "66.0  score for ep 77\n",
      "11.0  score for ep 78\n",
      "28.0  score for ep 79\n",
      "30.0  score for ep 80\n",
      "18.0  score for ep 81\n",
      "37.0  score for ep 82\n",
      "27.0  score for ep 83\n",
      "57.0  score for ep 84\n",
      "29.0  score for ep 85\n",
      "22.0  score for ep 86\n",
      "10.0  score for ep 87\n",
      "77.0  score for ep 88\n",
      "34.0  score for ep 89\n",
      "28.0  score for ep 90\n",
      "26.0  score for ep 91\n",
      "22.0  score for ep 92\n",
      "53.0  score for ep 93\n",
      "33.0  score for ep 94\n",
      "28.0  score for ep 95\n",
      "59.0  score for ep 96\n",
      "120.0  score for ep 97\n",
      "58.0  score for ep 98\n",
      "117.0  score for ep 99\n",
      "26.0  score for ep 100\n",
      "84.0  score for ep 101\n",
      "74.0  score for ep 102\n",
      "44.0  score for ep 103\n",
      "30.0  score for ep 104\n",
      "38.0  score for ep 105\n",
      "44.0  score for ep 106\n",
      "87.0  score for ep 107\n",
      "148.0  score for ep 108\n",
      "75.0  score for ep 109\n",
      "41.0  score for ep 110\n",
      "39.0  score for ep 111\n",
      "37.0  score for ep 112\n",
      "16.0  score for ep 113\n",
      "103.0  score for ep 114\n",
      "27.0  score for ep 115\n",
      "60.0  score for ep 116\n",
      "39.0  score for ep 117\n",
      "43.0  score for ep 118\n",
      "18.0  score for ep 119\n",
      "20.0  score for ep 120\n",
      "51.0  score for ep 121\n",
      "21.0  score for ep 122\n",
      "191.0  score for ep 123\n",
      "13.0  score for ep 124\n",
      "14.0  score for ep 125\n",
      "56.0  score for ep 126\n",
      "72.0  score for ep 127\n",
      "66.0  score for ep 128\n",
      "21.0  score for ep 129\n",
      "44.0  score for ep 130\n",
      "34.0  score for ep 131\n",
      "49.0  score for ep 132\n",
      "27.0  score for ep 133\n",
      "130.0  score for ep 134\n",
      "151.0  score for ep 135\n",
      "112.0  score for ep 136\n",
      "40.0  score for ep 137\n",
      "25.0  score for ep 138\n",
      "171.0  score for ep 139\n",
      "159.0  score for ep 140\n",
      "200.0  score for ep 141\n",
      "164.0  score for ep 142\n",
      "83.0  score for ep 143\n",
      "200.0  score for ep 144\n",
      "86.0  score for ep 145\n",
      "40.0  score for ep 146\n",
      "93.0  score for ep 147\n",
      "26.0  score for ep 148\n",
      "54.0  score for ep 149\n",
      "18.0  score for ep 150\n",
      "82.0  score for ep 151\n",
      "122.0  score for ep 152\n",
      "24.0  score for ep 153\n",
      "77.0  score for ep 154\n",
      "71.0  score for ep 155\n",
      "63.0  score for ep 156\n",
      "200.0  score for ep 157\n",
      "75.0  score for ep 158\n",
      "200.0  score for ep 159\n",
      "200.0  score for ep 160\n",
      "200.0  score for ep 161\n",
      "200.0  score for ep 162\n",
      "200.0  score for ep 163\n",
      "200.0  score for ep 164\n",
      "155.0  score for ep 165\n",
      "138.0  score for ep 166\n",
      "174.0  score for ep 167\n",
      "200.0  score for ep 168\n",
      "200.0  score for ep 169\n",
      "68.0  score for ep 170\n",
      "131.0  score for ep 171\n",
      "200.0  score for ep 172\n",
      "177.0  score for ep 173\n",
      "200.0  score for ep 174\n",
      "164.0  score for ep 175\n",
      "196.0  score for ep 176\n",
      "200.0  score for ep 177\n",
      "200.0  score for ep 178\n",
      "186.0  score for ep 179\n",
      "110.0  score for ep 180\n",
      "117.0  score for ep 181\n",
      "40.0  score for ep 182\n",
      "13.0  score for ep 183\n",
      "26.0  score for ep 184\n",
      "34.0  score for ep 185\n",
      "29.0  score for ep 186\n",
      "34.0  score for ep 187\n",
      "58.0  score for ep 188\n",
      "54.0  score for ep 189\n",
      "153.0  score for ep 190\n",
      "40.0  score for ep 191\n",
      "131.0  score for ep 192\n",
      "200.0  score for ep 193\n",
      "127.0  score for ep 194\n",
      "200.0  score for ep 195\n",
      "62.0  score for ep 196\n",
      "86.0  score for ep 197\n",
      "117.0  score for ep 198\n",
      "200.0  score for ep 199\n",
      "200.0  score for ep 200\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gym \n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "\n",
    "class QLearnCartPoleSolver():\n",
    "    def __init__(self, env, buckets=(6, 12), episodes=100, epsilon_decay_rate = 0.1, \n",
    "        decay=24, max_steps=100, batch_size = 64, min_lr=0.1, discount=1.0,min_epsilon=0.1):\n",
    "\n",
    "        self.env = env\n",
    "        self.action_size = self.env.action_space.n\n",
    "        self.discount=discount\n",
    "        self.buckets = buckets\n",
    "        self.min_lr = min_lr\n",
    "        self.min_epsilon = min_epsilon \n",
    "        self.episodes = episodes\n",
    "        self.decay = decay\n",
    "        self.epsilon_decay_rate = epsilon_decay_rate\n",
    "        self.max_steps = max_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.Q_Values = np.zeros(self.buckets +( self.action_size,))\n",
    "        self.upper_bounds = [\n",
    "            self.env.observation_space.high[2], math.radians(50)]\n",
    "        self.lower_bounds = [\n",
    "            self.env.observation_space.low[2], -math.radians(50)]\n",
    "\n",
    "\n",
    "    def get_epsilon(self, t):\n",
    "        return max(self.min_epsilon, min(1., 1. - math.log10((t + 1) / self.decay)))\n",
    "\n",
    "    def get_learning_rate(self, t):\n",
    "        return max(self.min_lr, min(1., 1. - math.log10((t + 1) / self.decay)))\n",
    "\n",
    "    def action(self, state):\n",
    "        return self.env.action_space.sample() if np.random.random() <= self.epsilon else np.argmax(self.Q_Values[state])\n",
    "\n",
    "    def updated_q_value(self, state, action, reward, new_state):\n",
    "        return (self.learning_rate * (reward + self.discount * np.max(self.Q_Values[new_state]) - self.Q_Values[state][action]))\n",
    "\n",
    "    def discretize_state(self, state):\n",
    "        _, _, angle, angle_velocity = state\n",
    "        est = KBinsDiscretizer(n_bins=self.buckets,\n",
    "                               encode='ordinal', strategy='uniform')\n",
    "        est.fit([self.lower_bounds, self.upper_bounds])\n",
    "        return tuple(map(int, est.transform([[angle, angle_velocity]])[0]))\n",
    "    \n",
    "    def train(self):\n",
    "        scores = []\n",
    "        for episode in range(self.episodes):\n",
    "            self.learning_rate = self.get_learning_rate(episode)\n",
    "            self.epsilon = self.get_epsilon(episode)\n",
    "            state = self.discretize_state(self.env.reset())\n",
    "            done = False\n",
    "            reward_current_ep = 0\n",
    "            step = 1\n",
    "            while not done:\n",
    "                # self.env.render()\n",
    "                action = self.action(state)\n",
    "                next_state, reward, done, _ = self.env.step(action) \n",
    "                next_state = self.discretize_state(next_state)\n",
    "                self.Q_Values[state][action] += self.updated_q_value(state, action, reward, next_state)\n",
    "                state = next_state\n",
    "                reward_current_ep += reward\n",
    "                # print(f\"Trainingsession {episode+1}:\", step, \"steps\")\n",
    "                step +=1\n",
    "            scores.append(reward_current_ep)\n",
    "            print(f\"{scores[episode]}  score for ep {episode+1}\")\n",
    "        print('Finished training!')\n",
    "        #self.env.close()\n",
    "            \n",
    "    def run(self):\n",
    "        done = False\n",
    "        current_state = self.discretize_state(self.env.reset())\n",
    "        score = 0\n",
    "        while not done:\n",
    "            self.env.render()\n",
    "            action = self.action(current_state)\n",
    "            observation, reward, done, _ = self.env.step(action)\n",
    "            new_state = self.discretize_state(observation)\n",
    "            current_state = new_state\n",
    "            score += reward\n",
    "        print(f\"score {score}\")\n",
    "        self.env.close()\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "model = QLearnCartPoleSolver(env, episodes=200)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 200.0\n"
     ]
    }
   ],
   "source": [
    "model.run()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7291e4b392a32fbfa525b87d1bbd0a3d888adf3d0deca0c205c61b9e7284b82"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
