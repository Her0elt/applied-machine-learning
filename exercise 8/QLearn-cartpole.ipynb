{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://youtube.com/watch?v=qhRNvCVVJaA\n",
    "#https://www.youtube.com/watch?v=mo96Nqlo1L8\n",
    "#https://www.youtube.com/watch?v=HGeI30uATws\n",
    "#https://www.datamachinist.com/reinforcement-learning/part-6-q-learning-for-continuous-state-problems/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01020568 -0.01720916 -0.02911566 -0.00277115]\n",
      "(2, 6)\n",
      "14.0  score for ep 1\n",
      "[ 0.01630077  0.02926186  0.00213988 -0.03506989]\n",
      "(3, 5)\n",
      "25.0  score for ep 2\n",
      "[-0.01410539  0.03318221 -0.04330508 -0.01566053]\n",
      "(2, 5)\n",
      "30.0  score for ep 3\n",
      "[-0.01424017  0.03050586  0.03095977  0.03401666]\n",
      "(3, 6)\n",
      "15.0  score for ep 4\n",
      "[-0.02286044 -0.0320023   0.01693328 -0.0462225 ]\n",
      "(2, 5)\n",
      "57.0  score for ep 5\n",
      "[ 0.04574633 -0.00859948 -0.01423842 -0.03772189]\n",
      "(3, 5)\n",
      "91.0  score for ep 6\n",
      "[-0.04518612  0.01934939 -0.03375217  0.0233156 ]\n",
      "(3, 5)\n",
      "14.0  score for ep 7\n",
      "[ 0.04924644 -0.00618811  0.00912105  0.00464763]\n",
      "(2, 6)\n",
      "23.0  score for ep 8\n",
      "[ 0.04062912 -0.04972913  0.04796371  0.00341724]\n",
      "(3, 5)\n",
      "14.0  score for ep 9\n",
      "[ 0.00227795 -0.02198212  0.03001086  0.0203116 ]\n",
      "(2, 6)\n",
      "16.0  score for ep 10\n",
      "[-0.01066782 -0.01173394 -0.04169104  0.02327296]\n",
      "(2, 5)\n",
      "18.0  score for ep 11\n",
      "[-0.00212682  0.0404127   0.03814228 -0.02790559]\n",
      "(3, 6)\n",
      "25.0  score for ep 12\n",
      "[-0.03047789 -0.01602721 -0.0036897   0.03104759]\n",
      "(3, 5)\n",
      "51.0  score for ep 13\n",
      "[ 0.00827387 -0.02631905  0.03402048 -0.02169983]\n",
      "(2, 6)\n",
      "14.0  score for ep 14\n",
      "[-0.04271588  0.01985126 -0.02878442  0.04715549]\n",
      "(2, 5)\n",
      "11.0  score for ep 15\n",
      "[ 0.02601438 -0.0428567   0.03873881  0.00879839]\n",
      "(2, 5)\n",
      "36.0  score for ep 16\n",
      "[-0.03488221 -0.02745234  0.0306776   0.03544863]\n",
      "(2, 5)\n",
      "12.0  score for ep 17\n",
      "[-0.04066411  0.01266771  0.02659418  0.04690164]\n",
      "(3, 5)\n",
      "11.0  score for ep 18\n",
      "[ 0.00032656  0.01535216  0.02260718 -0.02582227]\n",
      "(3, 5)\n",
      "15.0  score for ep 19\n",
      "[ 0.04635058  0.02491214 -0.01726272 -0.00880278]\n",
      "(3, 6)\n",
      "23.0  score for ep 20\n",
      "[-0.00928686  0.00481328 -0.01202338  0.01716167]\n",
      "(3, 5)\n",
      "14.0  score for ep 21\n",
      "[ 0.00429398 -0.03032785 -0.00339188 -0.02880283]\n",
      "(3, 5)\n",
      "22.0  score for ep 22\n",
      "[-0.01105011  0.00314319  0.02841463  0.00596875]\n",
      "(2, 6)\n",
      "16.0  score for ep 23\n",
      "[ 0.02791957  0.0326817  -0.04826412  0.00631119]\n",
      "(2, 6)\n",
      "17.0  score for ep 24\n",
      "[ 0.00590538  0.00811913 -0.0132552   0.00743724]\n",
      "(3, 5)\n",
      "28.0  score for ep 25\n",
      "[ 0.01400512 -0.03434467 -0.00973973 -0.00494438]\n",
      "(3, 6)\n",
      "14.0  score for ep 26\n",
      "[ 0.02517023 -0.03407372  0.03892845 -0.01735328]\n",
      "(2, 5)\n",
      "20.0  score for ep 27\n",
      "[ 0.00702873 -0.01490604 -0.04103664 -0.01141703]\n",
      "(2, 6)\n",
      "21.0  score for ep 28\n",
      "[-0.0258408  -0.02218008 -0.03055478  0.01494119]\n",
      "(2, 6)\n",
      "21.0  score for ep 29\n",
      "[-0.02004461  0.03256951 -0.04607566  0.00544362]\n",
      "(2, 6)\n",
      "20.0  score for ep 30\n",
      "[-0.01966388 -0.00917483 -0.01566339 -0.03747723]\n",
      "(2, 5)\n",
      "52.0  score for ep 31\n",
      "[ 0.04625782  0.02081342 -0.03628348  0.01751983]\n",
      "(2, 6)\n",
      "24.0  score for ep 32\n",
      "[-0.01863142  0.00569455  0.03468896  0.03910495]\n",
      "(3, 6)\n",
      "14.0  score for ep 33\n",
      "[-0.04079479  0.00840212  0.01488681  0.00537154]\n",
      "(2, 5)\n",
      "31.0  score for ep 34\n",
      "[-0.03576865 -0.02288087  0.0395312   0.03648329]\n",
      "(2, 5)\n",
      "27.0  score for ep 35\n",
      "[ 0.02279307  0.03747263 -0.00487258 -0.00922166]\n",
      "(2, 6)\n",
      "12.0  score for ep 36\n",
      "[ 0.04196225 -0.04358683 -0.04134836 -0.04986138]\n",
      "(3, 5)\n",
      "13.0  score for ep 37\n",
      "[ 0.02802298  0.00026367 -0.00843162 -0.01892929]\n",
      "(2, 6)\n",
      "22.0  score for ep 38\n",
      "[ 0.00591414 -0.02657456  0.00893678  0.03460065]\n",
      "(2, 6)\n",
      "45.0  score for ep 39\n",
      "[-0.01248933  0.04433158  0.00304153  0.01037775]\n",
      "(2, 5)\n",
      "12.0  score for ep 40\n",
      "[-0.00064144  0.02657318 -0.0433245  -0.04049418]\n",
      "(3, 6)\n",
      "14.0  score for ep 41\n",
      "[ 0.01050245 -0.00504984 -0.026705    0.02654652]\n",
      "(2, 6)\n",
      "11.0  score for ep 42\n",
      "[-0.01885347 -0.00861494  0.0150646  -0.00769838]\n",
      "(3, 5)\n",
      "16.0  score for ep 43\n",
      "[0.00736308 0.03733963 0.03037219 0.00018085]\n",
      "(3, 6)\n",
      "28.0  score for ep 44\n",
      "[-0.03118651  0.02174376  0.04999108 -0.04987732]\n",
      "(3, 5)\n",
      "12.0  score for ep 45\n",
      "[-0.03321258 -0.01844579  0.02533675  0.01969757]\n",
      "(3, 6)\n",
      "11.0  score for ep 46\n",
      "[ 0.03226573  0.03484133  0.00216148 -0.02239158]\n",
      "(2, 6)\n",
      "12.0  score for ep 47\n",
      "[-0.0140272   0.03552921  0.01035037 -0.01104452]\n",
      "(3, 5)\n",
      "16.0  score for ep 48\n",
      "[ 0.04349301  0.03027202 -0.00716376  0.00318749]\n",
      "(2, 6)\n",
      "15.0  score for ep 49\n",
      "[-0.00500461  0.03757986  0.01812455  0.00902646]\n",
      "(2, 6)\n",
      "18.0  score for ep 50\n",
      "[-0.0117728  -0.04672362 -0.04247881  0.03864641]\n",
      "(2, 6)\n",
      "16.0  score for ep 51\n",
      "[-0.03555147 -0.02616834 -0.027417   -0.01218818]\n",
      "(3, 6)\n",
      "11.0  score for ep 52\n",
      "[-0.02743832  0.01615922  0.02458629 -0.02447724]\n",
      "(2, 5)\n",
      "22.0  score for ep 53\n",
      "[-0.03227679 -0.00034715 -0.03530608  0.02467812]\n",
      "(2, 5)\n",
      "15.0  score for ep 54\n",
      "[ 0.03005874  0.04836494 -0.04687612  0.01429272]\n",
      "(2, 5)\n",
      "29.0  score for ep 55\n",
      "[-0.01924903 -0.00648427  0.04954121 -0.03210397]\n",
      "(3, 5)\n",
      "12.0  score for ep 56\n",
      "[ 0.02004656 -0.04060483 -0.03718547  0.03188055]\n",
      "(3, 6)\n",
      "26.0  score for ep 57\n",
      "[ 0.0151402   0.00115338 -0.02421645  0.0002485 ]\n",
      "(2, 6)\n",
      "19.0  score for ep 58\n",
      "[0.01504717 0.01253936 0.02854364 0.03131413]\n",
      "(2, 5)\n",
      "27.0  score for ep 59\n",
      "[ 0.01915854 -0.0098075  -0.03953965  0.01836026]\n",
      "(3, 6)\n",
      "12.0  score for ep 60\n",
      "[ 0.03268805  0.03882626 -0.03164461  0.04708005]\n",
      "(3, 6)\n",
      "27.0  score for ep 61\n",
      "[-0.04035214 -0.04222753  0.02512157 -0.04360759]\n",
      "(3, 5)\n",
      "15.0  score for ep 62\n",
      "[-0.04532812  0.03801067 -0.02383075  0.00572537]\n",
      "(2, 6)\n",
      "11.0  score for ep 63\n",
      "[-0.03702679  0.0338535   0.00888209 -0.03987852]\n",
      "(2, 6)\n",
      "12.0  score for ep 64\n",
      "[-0.00425498  0.04286821  0.03309911 -0.04445511]\n",
      "(3, 5)\n",
      "9.0  score for ep 65\n",
      "[-0.02575689 -0.01104692 -0.02907289  0.02413784]\n",
      "(2, 6)\n",
      "20.0  score for ep 66\n",
      "[0.04536651 0.03566374 0.04491342 0.033576  ]\n",
      "(2, 5)\n",
      "36.0  score for ep 67\n",
      "[ 0.01140464  0.01595472 -0.04214896  0.0375169 ]\n",
      "(2, 5)\n",
      "40.0  score for ep 68\n",
      "[-0.02429253 -0.00283736 -0.02236127  0.00591221]\n",
      "(2, 6)\n",
      "28.0  score for ep 69\n",
      "[ 0.03306641 -0.03280488  0.00322593  0.02666451]\n",
      "(3, 5)\n",
      "21.0  score for ep 70\n",
      "[-0.04747701 -0.03461451  0.02623089 -0.01840746]\n",
      "(3, 5)\n",
      "11.0  score for ep 71\n",
      "[ 0.03531264 -0.02630068  0.00065009  0.03756947]\n",
      "(2, 6)\n",
      "15.0  score for ep 72\n",
      "[-0.00018853  0.04517901  0.0195605   0.03286947]\n",
      "(2, 5)\n",
      "43.0  score for ep 73\n",
      "[-0.03013954 -0.00706138  0.03342259 -0.03572001]\n",
      "(3, 5)\n",
      "32.0  score for ep 74\n",
      "[-0.00739724 -0.04465093 -0.0272278  -0.04037136]\n",
      "(2, 6)\n",
      "20.0  score for ep 75\n",
      "[-0.0044739  -0.00024399 -0.0364071   0.00064437]\n",
      "(2, 5)\n",
      "12.0  score for ep 76\n",
      "[-0.00734694 -0.04096059 -0.04042336  0.01932208]\n",
      "(3, 5)\n",
      "13.0  score for ep 77\n",
      "[-0.04941941  0.03876555 -0.02246842 -0.00307054]\n",
      "(2, 5)\n",
      "15.0  score for ep 78\n",
      "[-0.01841624 -0.02685888 -0.00920992  0.02723692]\n",
      "(2, 6)\n",
      "65.0  score for ep 79\n",
      "[-0.00592596  0.01830673 -0.01255333 -0.03987064]\n",
      "(3, 5)\n",
      "99.0  score for ep 80\n",
      "[-0.00375658  0.04450454  0.02928459 -0.00801486]\n",
      "(3, 6)\n",
      "35.0  score for ep 81\n",
      "[-0.0215574  -0.03787924  0.02778942 -0.01172938]\n",
      "(2, 5)\n",
      "33.0  score for ep 82\n",
      "[-0.03510834  0.02240891  0.00967919 -0.02594462]\n",
      "(3, 5)\n",
      "87.0  score for ep 83\n",
      "[-0.02859365  0.0295177   0.04068596 -0.00636502]\n",
      "(2, 5)\n",
      "32.0  score for ep 84\n",
      "[-0.04681297 -0.01009726  0.01657034 -0.00857535]\n",
      "(3, 5)\n",
      "31.0  score for ep 85\n",
      "[0.00568269 0.0082163  0.03954702 0.01048112]\n",
      "(3, 5)\n",
      "107.0  score for ep 86\n",
      "[-0.0178324   0.04016656  0.01521901  0.04727196]\n",
      "(2, 5)\n",
      "18.0  score for ep 87\n",
      "[-0.02769241  0.03831867  0.02337762  0.04252236]\n",
      "(3, 5)\n",
      "84.0  score for ep 88\n",
      "[-0.02215238  0.03131063  0.02795011  0.00456404]\n",
      "(2, 6)\n",
      "11.0  score for ep 89\n",
      "[-0.00747634 -0.00725598  0.03441479 -0.02627702]\n",
      "(2, 5)\n",
      "13.0  score for ep 90\n",
      "[-0.04126539 -0.03806402 -0.00288079 -0.00470424]\n",
      "(3, 6)\n",
      "63.0  score for ep 91\n",
      "[ 0.04839325  0.02288896  0.03476557 -0.0015581 ]\n",
      "(3, 6)\n",
      "53.0  score for ep 92\n",
      "[ 0.02559997  0.04048704  0.02291103 -0.01436892]\n",
      "(3, 5)\n",
      "33.0  score for ep 93\n",
      "[ 0.00964574  0.04644963  0.02992624 -0.01183974]\n",
      "(3, 5)\n",
      "33.0  score for ep 94\n",
      "[-0.04980272 -0.03327787  0.03179499 -0.04374836]\n",
      "(2, 6)\n",
      "17.0  score for ep 95\n",
      "[ 0.03986951 -0.04442864 -0.04306843  0.04734444]\n",
      "(3, 5)\n",
      "14.0  score for ep 96\n",
      "[-0.01162096 -0.02121192 -0.04082065  0.03288747]\n",
      "(3, 6)\n",
      "27.0  score for ep 97\n",
      "[-0.02826819 -0.04146824 -0.02651505  0.04428572]\n",
      "(2, 6)\n",
      "17.0  score for ep 98\n",
      "[ 0.02539102 -0.01277098  0.01774234  0.0100757 ]\n",
      "(3, 6)\n",
      "36.0  score for ep 99\n",
      "[ 0.01185681  0.02087142  0.01688299 -0.00646471]\n",
      "(2, 6)\n",
      "26.0  score for ep 100\n",
      "[-0.0269121  -0.01001179 -0.03892993  0.01480975]\n",
      "(2, 5)\n",
      "67.0  score for ep 101\n",
      "[ 0.00745058 -0.02697924 -0.01138654 -0.02053348]\n",
      "(2, 5)\n",
      "27.0  score for ep 102\n",
      "[ 0.03580598  0.00577537 -0.01972821 -0.03409153]\n",
      "(3, 5)\n",
      "32.0  score for ep 103\n",
      "[-0.03663046 -0.02544498  0.03825299  0.01652203]\n",
      "(2, 6)\n",
      "17.0  score for ep 104\n",
      "[ 0.0385552   0.03803177  0.01399484 -0.0071511 ]\n",
      "(3, 5)\n",
      "22.0  score for ep 105\n",
      "[0.04659479 0.04027449 0.02699546 0.04126474]\n",
      "(3, 5)\n",
      "35.0  score for ep 106\n",
      "[-0.02230095  0.00326085 -0.02626496 -0.01516312]\n",
      "(3, 5)\n",
      "28.0  score for ep 107\n",
      "[-0.01318962 -0.04076286  0.03547     0.0328566 ]\n",
      "(2, 6)\n",
      "20.0  score for ep 108\n",
      "[-0.03803341 -0.01650674 -0.03861498 -0.00535761]\n",
      "(2, 6)\n",
      "34.0  score for ep 109\n",
      "[-0.04923613  0.04276054 -0.0228593   0.02589732]\n",
      "(2, 6)\n",
      "47.0  score for ep 110\n",
      "[-0.03849089  0.01199992 -0.00067302  0.00621685]\n",
      "(3, 6)\n",
      "31.0  score for ep 111\n",
      "[ 0.03367905  0.03610947  0.03766486 -0.03332036]\n",
      "(3, 6)\n",
      "22.0  score for ep 112\n",
      "[ 0.04344448  0.01530726 -0.00591097 -0.00966185]\n",
      "(2, 5)\n",
      "101.0  score for ep 113\n",
      "[-0.04011074  0.03824927 -0.00033683 -0.04981953]\n",
      "(2, 5)\n",
      "156.0  score for ep 114\n",
      "[-0.04985353  0.01052323 -0.04499727 -0.04220561]\n",
      "(2, 6)\n",
      "26.0  score for ep 115\n",
      "[ 0.01862017 -0.01214217 -0.04816722  0.03705575]\n",
      "(2, 5)\n",
      "44.0  score for ep 116\n",
      "[-0.04860953  0.00456758  0.0110831  -0.0347504 ]\n",
      "(3, 6)\n",
      "198.0  score for ep 117\n",
      "[-0.01529234  0.0373629   0.03550263  0.00877672]\n",
      "(3, 6)\n",
      "179.0  score for ep 118\n",
      "[-0.0468186  -0.01044947 -0.00769928 -0.00266158]\n",
      "(2, 6)\n",
      "184.0  score for ep 119\n",
      "[ 0.01210887  0.02468945 -0.04152835 -0.04101006]\n",
      "(2, 5)\n",
      "165.0  score for ep 120\n",
      "[-0.0297288   0.04558338 -0.04570065  0.03795706]\n",
      "(3, 5)\n",
      "88.0  score for ep 121\n",
      "[-0.01049524 -0.016094   -0.02875754 -0.0409423 ]\n",
      "(2, 6)\n",
      "15.0  score for ep 122\n",
      "[-0.00771221  0.04042454 -0.00301103  0.02248687]\n",
      "(3, 6)\n",
      "23.0  score for ep 123\n",
      "[-0.00145751  0.04127663 -0.03831704  0.0075793 ]\n",
      "(2, 6)\n",
      "32.0  score for ep 124\n",
      "[-0.00576556  0.02585306 -0.03618131  0.00220311]\n",
      "(2, 5)\n",
      "51.0  score for ep 125\n",
      "[ 0.0219999  -0.04280142  0.0335889   0.04827842]\n",
      "(3, 6)\n",
      "28.0  score for ep 126\n",
      "[-0.01272785 -0.02801159  0.01282654 -0.03858903]\n",
      "(3, 5)\n",
      "130.0  score for ep 127\n",
      "[ 0.0151503  -0.04022921  0.03560049  0.0365967 ]\n",
      "(2, 5)\n",
      "128.0  score for ep 128\n",
      "[ 0.00292048  0.03343198  0.02805761 -0.01071915]\n",
      "(2, 5)\n",
      "30.0  score for ep 129\n",
      "[ 0.00474454  0.03907715  0.01556915 -0.02161541]\n",
      "(3, 6)\n",
      "99.0  score for ep 130\n",
      "[ 3.7110761e-02  3.3663578e-02  2.1827100e-02 -5.4037802e-05]\n",
      "(2, 6)\n",
      "112.0  score for ep 131\n",
      "[ 0.00940977  0.03591996 -0.03334872 -0.02842797]\n",
      "(2, 6)\n",
      "37.0  score for ep 132\n",
      "[-0.01618109  0.04818299  0.03462614  0.01728421]\n",
      "(3, 5)\n",
      "69.0  score for ep 133\n",
      "[ 0.03916007 -0.03388645 -0.01238113  0.03921311]\n",
      "(2, 6)\n",
      "27.0  score for ep 134\n",
      "[ 0.01167508 -0.03401153 -0.01402878  0.03136288]\n",
      "(2, 6)\n",
      "90.0  score for ep 135\n",
      "[-0.00836998 -0.03158535 -0.02057718  0.02002894]\n",
      "(3, 6)\n",
      "24.0  score for ep 136\n",
      "[-0.02471174 -0.0352529   0.03945481  0.02525965]\n",
      "(2, 5)\n",
      "200.0  score for ep 137\n",
      "[-0.0318495   0.00407959 -0.01041644 -0.01061465]\n",
      "(2, 5)\n",
      "200.0  score for ep 138\n",
      "[ 0.04220744 -0.02045329  0.01761261  0.04816851]\n",
      "(3, 5)\n",
      "200.0  score for ep 139\n",
      "[-0.00382908  0.01704259 -0.01638875  0.04972989]\n",
      "(3, 5)\n",
      "200.0  score for ep 140\n",
      "[ 0.01009487 -0.01560625  0.00678068  0.04503945]\n",
      "(3, 5)\n",
      "200.0  score for ep 141\n",
      "[-0.03065155  0.04866904 -0.0102888  -0.0456338 ]\n",
      "(3, 5)\n",
      "200.0  score for ep 142\n",
      "[-0.01265287  0.04590347 -0.00356512 -0.02066575]\n",
      "(2, 5)\n",
      "200.0  score for ep 143\n",
      "[-0.00615146  0.03207195  0.01781032  0.03022607]\n",
      "(3, 6)\n",
      "200.0  score for ep 144\n",
      "[ 0.00264683  0.03013294 -0.00769704  0.02363962]\n",
      "(2, 5)\n",
      "200.0  score for ep 145\n",
      "[-0.00212329 -0.04285197  0.04101424 -0.03411898]\n",
      "(3, 6)\n",
      "81.0  score for ep 146\n",
      "[-0.0283318  -0.02079357  0.0037916  -0.02812308]\n",
      "(2, 5)\n",
      "151.0  score for ep 147\n",
      "[ 0.00336927 -0.01850954 -0.0450771  -0.01899708]\n",
      "(2, 5)\n",
      "200.0  score for ep 148\n",
      "[-0.00619301  0.0451823  -0.03071773 -0.03156856]\n",
      "(3, 6)\n",
      "14.0  score for ep 149\n",
      "[ 0.04201641 -0.03580352 -0.03555313 -0.03174477]\n",
      "(3, 5)\n",
      "200.0  score for ep 150\n",
      "[-0.04282357  0.02880808 -0.03451212  0.02859435]\n",
      "(2, 5)\n",
      "61.0  score for ep 151\n",
      "[0.04512059 0.01794824 0.04104211 0.03874119]\n",
      "(3, 5)\n",
      "119.0  score for ep 152\n",
      "[ 0.01305924  0.01457525 -0.04117326  0.04555142]\n",
      "(2, 5)\n",
      "69.0  score for ep 153\n",
      "[-0.04200961 -0.01920789  0.00170798  0.0325461 ]\n",
      "(2, 6)\n",
      "146.0  score for ep 154\n",
      "[ 0.04584391 -0.01041347  0.04343271 -0.02020431]\n",
      "(2, 6)\n",
      "137.0  score for ep 155\n",
      "[0.02444617 0.03467371 0.00151035 0.02759353]\n",
      "(2, 5)\n",
      "77.0  score for ep 156\n",
      "[-0.03739801  0.01760538  0.0195923  -0.04347876]\n",
      "(3, 5)\n",
      "200.0  score for ep 157\n",
      "[ 0.04146815 -0.02163189  0.01905128  0.03088824]\n",
      "(2, 6)\n",
      "128.0  score for ep 158\n",
      "[ 0.04283756  0.00140583 -0.04605204  0.04491695]\n",
      "(2, 6)\n",
      "200.0  score for ep 159\n",
      "[-0.04777261 -0.02183233 -0.03639223  0.02627853]\n",
      "(3, 5)\n",
      "119.0  score for ep 160\n",
      "[ 0.0320936  -0.04814628 -0.04169467 -0.02742956]\n",
      "(3, 5)\n",
      "192.0  score for ep 161\n",
      "[-0.04814162  0.047528    0.04877046  0.00703309]\n",
      "(2, 5)\n",
      "63.0  score for ep 162\n",
      "[-0.03152019 -0.0173245   0.01084074  0.00666754]\n",
      "(2, 6)\n",
      "56.0  score for ep 163\n",
      "[ 0.02867932  0.01981795 -0.00072019  0.02918594]\n",
      "(2, 5)\n",
      "17.0  score for ep 164\n",
      "[-0.02303506  0.01783411 -0.02514502  0.00324019]\n",
      "(2, 5)\n",
      "26.0  score for ep 165\n",
      "[-0.00089622  0.00118672 -0.04145414 -0.03255907]\n",
      "(2, 6)\n",
      "60.0  score for ep 166\n",
      "[-0.03530776 -0.03668401  0.0167599  -0.03367238]\n",
      "(2, 5)\n",
      "31.0  score for ep 167\n",
      "[-0.0274156   0.02745062 -0.02817076  0.02754914]\n",
      "(3, 5)\n",
      "110.0  score for ep 168\n",
      "[0.02780276 0.00611977 0.00219248 0.01028652]\n",
      "(2, 6)\n",
      "21.0  score for ep 169\n",
      "[ 0.00505303 -0.00551131  0.00841313 -0.02796318]\n",
      "(3, 5)\n",
      "35.0  score for ep 170\n",
      "[-0.02294751  0.03627609  0.01563376  0.00451442]\n",
      "(3, 6)\n",
      "15.0  score for ep 171\n",
      "[-0.0454424   0.04569551 -0.03285295  0.04099891]\n",
      "(2, 5)\n",
      "200.0  score for ep 172\n",
      "[-0.00354118 -0.02357408  0.01759282  0.02839128]\n",
      "(2, 5)\n",
      "200.0  score for ep 173\n",
      "[-0.00373016 -0.04283694 -0.02832273 -0.01257133]\n",
      "(2, 5)\n",
      "178.0  score for ep 174\n",
      "[-0.01721198 -0.03942313  0.01839236 -0.00928297]\n",
      "(3, 5)\n",
      "200.0  score for ep 175\n",
      "[ 0.04305322 -0.00466508 -0.04543633  0.02991402]\n",
      "(2, 6)\n",
      "79.0  score for ep 176\n",
      "[ 0.00755006 -0.03280535 -0.01001848 -0.04568701]\n",
      "(3, 5)\n",
      "45.0  score for ep 177\n",
      "[ 0.04043385  0.00917288 -0.01479156 -0.00270797]\n",
      "(3, 6)\n",
      "42.0  score for ep 178\n",
      "[-0.01822385  0.03437694 -0.00665965  0.03252006]\n",
      "(3, 5)\n",
      "57.0  score for ep 179\n",
      "[ 0.0469713  -0.04855612  0.0019366  -0.00019955]\n",
      "(3, 6)\n",
      "41.0  score for ep 180\n",
      "[ 0.04862682  0.01090841 -0.02201195  0.0058667 ]\n",
      "(3, 5)\n",
      "63.0  score for ep 181\n",
      "[0.00573552 0.01917499 0.02066059 0.0285677 ]\n",
      "(2, 5)\n",
      "97.0  score for ep 182\n",
      "[-0.03303888  0.04896381  0.00932559  0.00914226]\n",
      "(2, 5)\n",
      "80.0  score for ep 183\n",
      "[-0.02590174  0.03819627  0.03581381  0.04737972]\n",
      "(2, 6)\n",
      "200.0  score for ep 184\n",
      "[ 0.02754672 -0.02823838  0.02707472  0.02437829]\n",
      "(3, 6)\n",
      "200.0  score for ep 185\n",
      "[ 0.02763254  0.00142235 -0.01003595  0.04848075]\n",
      "(2, 6)\n",
      "200.0  score for ep 186\n",
      "[-0.03958783 -0.04408608 -0.00546258  0.02247611]\n",
      "(3, 5)\n",
      "200.0  score for ep 187\n",
      "[-0.02565311  0.02855834 -0.03422065 -0.04161816]\n",
      "(3, 5)\n",
      "102.0  score for ep 188\n",
      "[ 0.01054715 -0.00406575  0.00133227 -0.04172829]\n",
      "(3, 6)\n",
      "200.0  score for ep 189\n",
      "[ 0.03456469  0.04965558 -0.00701169 -0.020887  ]\n",
      "(2, 6)\n",
      "200.0  score for ep 190\n",
      "[-0.03632153 -0.0065267  -0.00297819  0.0258792 ]\n",
      "(2, 6)\n",
      "200.0  score for ep 191\n",
      "[-0.01322914 -0.04399235  0.01645944  0.04484534]\n",
      "(3, 5)\n",
      "200.0  score for ep 192\n",
      "[ 0.0058817   0.02754067 -0.01806272 -0.00279024]\n",
      "(3, 6)\n",
      "200.0  score for ep 193\n",
      "[-0.03691963  0.04954598  0.02994004  0.00498588]\n",
      "(3, 5)\n",
      "173.0  score for ep 194\n",
      "[-0.00282279  0.03953596  0.03313329  0.03888153]\n",
      "(2, 6)\n",
      "200.0  score for ep 195\n",
      "[ 0.03433097  0.03964188  0.0267628  -0.02585687]\n",
      "(3, 6)\n",
      "200.0  score for ep 196\n",
      "[ 0.04127136 -0.04926052  0.02510339  0.01028523]\n",
      "(2, 6)\n",
      "200.0  score for ep 197\n",
      "[ 0.00825974 -0.01245034  0.03458791  0.01944893]\n",
      "(3, 6)\n",
      "200.0  score for ep 198\n",
      "[ 0.03847403 -0.04524921 -0.01546127 -0.02690182]\n",
      "(2, 6)\n",
      "200.0  score for ep 199\n",
      "[ 0.03114932 -0.01307562  0.02602763 -0.01975808]\n",
      "(2, 6)\n",
      "200.0  score for ep 200\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gym \n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "\n",
    "class QLearnCartPoleSolver():\n",
    "    def __init__(self, env, buckets=(6, 12), episodes=100, epsilon_decay_rate = 0.1, \n",
    "        decay=24, max_steps=100, batch_size = 64, min_lr=0.1, discount=1.0,min_epsilon=0.1):\n",
    "\n",
    "        self.env = env\n",
    "        self.action_size = self.env.action_space.n\n",
    "        self.discount=discount\n",
    "        self.buckets = buckets\n",
    "        self.min_lr = min_lr\n",
    "        self.min_epsilon = min_epsilon \n",
    "        self.episodes = episodes\n",
    "        self.decay = decay\n",
    "        self.epsilon_decay_rate = epsilon_decay_rate\n",
    "        self.max_steps = max_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.Q_Values = np.zeros(self.buckets +( self.action_size,))\n",
    "        self.upper_bounds = [\n",
    "            self.env.observation_space.high[2], math.radians(50)]\n",
    "        self.lower_bounds = [\n",
    "            self.env.observation_space.low[2], -math.radians(50)]\n",
    "\n",
    "\n",
    "    def get_epsilon(self, t):\n",
    "        return max(self.min_epsilon, min(1., 1. - math.log10((t + 1) / self.decay)))\n",
    "\n",
    "    def get_learning_rate(self, t):\n",
    "        return max(self.min_lr, min(1., 1. - math.log10((t + 1) / self.decay)))\n",
    "\n",
    "    def action(self, state):\n",
    "        return self.env.action_space.sample() if np.random.random() <= self.epsilon else np.argmax(self.Q_Values[state])\n",
    "\n",
    "    def updated_q_value(self, state, action, reward, new_state):\n",
    "        return (self.learning_rate * (reward + self.discount * np.max(self.Q_Values[new_state]) - self.Q_Values[state][action]))\n",
    "\n",
    "    def discretize_state(self, state):\n",
    "        _, _, angle, angle_velocity = state\n",
    "        est = KBinsDiscretizer(n_bins=self.buckets,\n",
    "                               encode='ordinal', strategy='uniform')\n",
    "        est.fit([self.lower_bounds, self.upper_bounds])\n",
    "        return tuple(map(int, est.transform([[angle, angle_velocity]])[0]))\n",
    "    \n",
    "    def train(self):\n",
    "        scores = []\n",
    "        for episode in range(self.episodes):\n",
    "            self.learning_rate = self.get_learning_rate(episode)\n",
    "            self.epsilon = self.get_epsilon(episode)\n",
    "            state = self.discretize_state(self.env.reset())\n",
    "            done = False\n",
    "            reward_current_ep = 0\n",
    "            step = 1\n",
    "            while not done:\n",
    "                # self.env.render()\n",
    "                action = self.action(state)\n",
    "                next_state, reward, done, _ = self.env.step(action) \n",
    "                next_state = self.discretize_state(next_state)\n",
    "                self.Q_Values[state][action] += self.updated_q_value(state, action, reward, next_state)\n",
    "                state = next_state\n",
    "                reward_current_ep += reward\n",
    "                # print(f\"Trainingsession {episode+1}:\", step, \"steps\")\n",
    "                step +=1\n",
    "            scores.append(reward_current_ep)\n",
    "            print(f\"{scores[episode]}  score for ep {episode+1}\")\n",
    "        print('Finished training!')\n",
    "        #self.env.close()\n",
    "            \n",
    "    def run(self):\n",
    "        done = False\n",
    "        current_state = self.discretize_state(self.env.reset())\n",
    "        score = 0\n",
    "        while not done:\n",
    "            self.env.render()\n",
    "            action = self.action(current_state)\n",
    "            observation, reward, done, _ = self.env.step(action)\n",
    "            new_state = self.discretize_state(observation)\n",
    "            current_state = new_state\n",
    "            score += reward\n",
    "        print(f\"score {score}\")\n",
    "        self.env.close()\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "model = QLearnCartPoleSolver(env, episodes=200)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 200.0\n"
     ]
    }
   ],
   "source": [
    "model.run()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
